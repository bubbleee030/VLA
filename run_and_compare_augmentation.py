#!/usr/bin/env python3
"""
æœ€çµ‚ç‰ˆå¯¦é©—ä¸»ç¨‹å¼ï¼šè³‡æ–™å¢é‡å‰å¾Œå°æ¯”å¯¦é©—

åŠŸèƒ½ï¼š
1. åˆ†åˆ¥åœ¨ã€ŒåŸå§‹ã€å’Œã€Œå¢é‡ã€è³‡æ–™é›†ä¸Šè¨“ç·´æ¨¡å‹ã€‚
2. å°‡å…©æ¬¡å¯¦é©—çš„æ—¥èªŒå’Œæ¨¡å‹å„²å­˜åˆ°ç¨ç«‹çš„è³‡æ–™å¤¾ï¼Œé¿å…è¦†è“‹ã€‚
3. è¨“ç·´çµæŸå¾Œï¼Œè‡ªå‹•ç”Ÿæˆé‡åŒ–åˆ†æå ±å‘Šèˆ‡è¦–è¦ºåŒ–å°æ¯”åœ–è¡¨ã€‚
"""

import argparse
import yaml
import torch
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import shutil
import numpy as np
from pytorch_lightning import Trainer, seed_everything
from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor
from pytorch_lightning.loggers import CSVLogger
from residual_controller.bridge_model import ResidualController
from residual_controller.controller_dataset import ControllerDataModule

# --- è¨­å®š Matplotlib å­—é«” ---
plt.rcParams['font.sans-serif'] = ['Noto Sans TC', 'Noto Sans CJK JP']
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")


def load_config(config_path):
    """Load and parse the YAML config file, ensuring correct data types."""
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    # --- ã€é‡è¦ä¿®æ­£ã€‘ç¢ºä¿ learning_rate æ˜¯æµ®é»æ•¸ ---
    # PyYAML æœƒå°‡ '1e-4' è®€æˆå­—ä¸²ï¼Œæˆ‘å€‘éœ€è¦æ‰‹å‹•è½‰æ›
    config['training']['learning_rate'] = float(config['training']['learning_rate'])
    
    # ç‚ºäº†ä¿éšªèµ·è¦‹ï¼Œä¹Ÿæª¢æŸ¥å…¶ä»–æ•¸å€¼å‹åˆ¥
    config['training']['epochs'] = int(config['training']['epochs'])
    config['training']['batch_size'] = int(config['training']['batch_size'])
    config['data']['num_workers'] = int(config['data']['num_workers'])
    config['model']['action_dim'] = int(config['model']['action_dim'])
    config['model']['obs_dim'] = int(config['model']['obs_dim'])
    config['model']['horizon'] = int(config['model']['horizon'])
    
    return config

def train_single_model(config, data_dir, modality, experiment_suffix):
    """
    è¨“ç·´å–®ä¸€æ¨¡å‹ï¼Œä¸¦å°‡çµæœå„²å­˜åˆ°å”¯ä¸€çš„è·¯å¾‘ã€‚
    """
    run_name = f"{modality}{experiment_suffix}"
    experiment_name = f"{'å®Œæ•´è§¸è¦º' if modality == 'tactile' else 'é€€åŒ–ç‰ˆ'} ({experiment_suffix.strip('_')})"
    
    print("\n" + "="*70)
    print(f"ğŸš€ é–‹å§‹è¨“ç·´ï¼š{experiment_name}")
    print(f"ğŸ”¬ å¯¦é©—åŸ·è¡Œåç¨± (Run Name): {run_name}")
    print(f"ğŸ“ è³‡æ–™ä¾†æº: {data_dir}")
    print("="*70)
    
    seed_everything(42, workers=True)
    
    # --- è¨­å®šå”¯ä¸€çš„è¼¸å‡ºè·¯å¾‘ ---
    output_dir = Path(config['checkpoint']['save_dir']) / run_name
    log_dir_root = Path(config['logging']['csv_dir'])
    
    # --- è‡ªå‹•æ¸…ç†èˆŠç´€éŒ„ (é‡è¦ï¼) ---
    if output_dir.exists():
        print(f"ğŸ§¹ æ¸…ç†èˆŠæ¨¡å‹ç›®éŒ„ï¼š{output_dir}")
        shutil.rmtree(output_dir)
    if (log_dir_root / run_name).exists():
        print(f"ğŸ§¹ æ¸…ç†èˆŠæ—¥èªŒç›®éŒ„ï¼š{log_dir_root / run_name}")
        shutil.rmtree(log_dir_root / run_name)
    output_dir.mkdir(parents=True, exist_ok=True)

    # --- è³‡æ–™æ¨¡çµ„ ---
    data_module = ControllerDataModule(
        h5_path_or_dir=data_dir,
        horizon=config['model']['horizon'],
        batch_size=config['training']['batch_size'],
        num_workers=config['data']['num_workers'],
        train_ratio=config['data']['train_ratio'],
        seed=config['data']['random_seed']
    )
    
    # --- æ¨¡å‹ ---
    model = ResidualController(
        modality=modality,
        lr=config['training']['learning_rate'],
        action_dim=config['model']['action_dim'],
        obs_dim=config['model']['obs_dim'],
        horizon=config['model']['horizon']
    )
    
    # --- Logger å’Œ Callbacks ---
    logger = CSVLogger(save_dir=str(log_dir_root), name=run_name, version=0)
    callbacks = [
        ModelCheckpoint(dirpath=str(output_dir), filename='best-{epoch:02d}-{val_loss:.4f}', monitor='val_loss', mode='min', save_top_k=1, save_last=True),
        LearningRateMonitor(logging_interval='epoch'),
    ]
    
    # --- è¨“ç·´å™¨ ---
    trainer = Trainer(
        max_epochs=config['training']['epochs'],
        accelerator='gpu' if torch.cuda.is_available() else 'cpu',
        devices=1,
        callbacks=callbacks,
        logger=logger,
        log_every_n_steps=config['logging']['log_every_n_steps'],
    )
    
    # --- é–‹å§‹è¨“ç·´èˆ‡æ¸¬è©¦ ---
    trainer.fit(model, datamodule=data_module)
    trainer.test(model, datamodule=data_module, ckpt_path='best')
    
    log_file_path = Path(logger.log_dir) / 'metrics.csv'
    print(f"\nâœ… {experiment_name} è¨“ç·´å®Œæˆï¼")
    print(f"ğŸ“Š è¨˜éŒ„å·²å„²å­˜è‡³ï¼š{log_file_path}\n")
    
    return str(log_file_path)

def analyze_and_plot(csv_path1, csv_path2, name1, name2, save_dir, version_tag):
    """Load logs from two experiments, generate a comparison report and plots."""
    
    df1 = pd.read_csv(csv_path1).dropna(subset=['epoch'])
    df2 = pd.read_csv(csv_path2).dropna(subset=['epoch'])

    save_path = Path(save_dir)
    save_path.mkdir(parents=True, exist_ok=True)
    
    # --- 1. Calculate Key Metrics ---
    metrics = {}
    for df, name in [(df1, name1), (df2, name2)]:
        metrics[name] = {
            'train_loss': df['train_loss_epoch'].dropna().iloc[-1],
            'test_loss': df['test_loss'].dropna().iloc[-1] if 'test_loss' in df.columns and not df['test_loss'].dropna().empty else float('nan'),
        }
        if not np.isnan(metrics[name]['test_loss']):
            metrics[name]['gap'] = (metrics[name]['test_loss'] - metrics[name]['train_loss']) / metrics[name]['train_loss'] * 100
        else:
            metrics[name]['gap'] = float('nan')

    # --- 2. Generate Quantitative Report (Corrected) ---
    print("\n" + "="*80)
    print("ğŸ“Š Data Augmentation Benefit Analysis Report")
    print("="*80)
    
    # --- ğŸ’¡ã€æ ¸å¿ƒä¿®æ­£ã€‘é å…ˆæ ¼å¼åŒ–æ‰€æœ‰éœ€è¦é¡¯ç¤ºçš„å­—ä¸² ---
    # é å…ˆè¨ˆç®—è®ŠåŒ–ç‡
    train_loss_change = (metrics[name2]["train_loss"]-metrics[name1]["train_loss"])/metrics[name1]["train_loss"]*100 if metrics[name1]["train_loss"] != 0 else float('inf')
    test_loss_change = (metrics[name2]["test_loss"]-metrics[name1]["test_loss"])/metrics[name1]["test_loss"]*100 if not np.isnan(metrics[name1]['test_loss']) and metrics[name1]['test_loss'] != 0 else float('inf')
    gap_change = metrics[name2]["gap"] - metrics[name1]["gap"] if not np.isnan(metrics[name1]['gap']) and not np.isnan(metrics[name2]['gap']) else float('nan')
    
    # å°‡æ‰€æœ‰éœ€è¦ç‰¹æ®Šæ ¼å¼çš„æ•¸å­—éƒ½è®Šæˆå­—ä¸²
    gap1_str = f"{metrics[name1]['gap']:+.1f}%" if not np.isnan(metrics[name1]['gap']) else "N/A"
    gap2_str = f"{metrics[name2]['gap']:+.1f}%" if not np.isnan(metrics[name2]['gap']) else "N/A"
    train_loss_change_str = f"{train_loss_change:+.1f}%"
    test_loss_change_str = f"{test_loss_change:+.1f}%"
    gap_change_str = f"{gap_change:+.1f} p.p." if not np.isnan(gap_change) else "N/A"

    # --- ç¾åœ¨æ‰€æœ‰çš„ print å‡½å¼éƒ½è®Šå¾—éå¸¸ç°¡å–® ---
    print(f"{'Metric':<20} | {name1:<25} | {name2:<25} | {'Change':<10}")
    print("-" * 80)
    print(f"{'Final Train Loss':<20} | {metrics[name1]['train_loss']:<25.6f} | {metrics[name2]['train_loss']:<25.6f} | {train_loss_change_str:<10}")
    print(f"{'Final Test Loss':<20} | {metrics[name1]['test_loss']:<25.6f} | {metrics[name2]['test_loss']:<25.6f} | {test_loss_change_str:<10}")
    print(f"{'Generalization Gap':<20} | {gap1_str:<25} | {gap2_str:<25} | {gap_change_str:<10}")
    print("-" * 80)
    
    # --- ç¹ªè£½åœ–è¡¨ ---
    plt.figure(figsize=(18, 8))
    fig, axes = plt.subplots(1, 2, figsize=(18, 7))
    fig.suptitle(f'Data Augmentation Benefit Analysis ({version_tag} vs 1x)', fontsize=20, weight='bold')
    
    # å·¦åœ–ï¼šå­¸ç¿’æ›²ç·š
    axes[0].plot(df1['epoch'], df1['train_loss_epoch'], 'o--', markersize=3, color='#2E86AB', label=f'Training Loss ({name1})')
    axes[0].plot(df1.dropna(subset=['test_loss'])['epoch'], df1.dropna(subset=['test_loss'])['test_loss'], 'o-', markersize=4, color='#2E86AB', label=f'Validation Loss ({name1})')
    axes[0].plot(df2['epoch'], df2['train_loss_epoch'], 's--', markersize=3, color='#A23B72', label=f'Training Loss ({name2})')
    axes[0].plot(df2.dropna(subset=['test_loss'])['epoch'], df2.dropna(subset=['test_loss'])['test_loss'], 's-', markersize=4, color='#A23B72', label=f'Validation Loss ({name2})')
    axes[0].set_title('Learning Curve Comparison', fontsize=14, fontweight='bold')
    axes[0].set_xlabel('Epoch', fontsize=12)
    axes[0].set_ylabel('Loss (MSE) - Log Scale', fontsize=12)
    axes[0].legend()
    axes[0].set_yscale('log')

    # å³åœ–ï¼šæœ€çµ‚æ¸¬è©¦ Loss
    labels = [name1, name2]
    final_test_losses = [metrics[name1]['test_loss'], metrics[name2]['test_loss']]
    bars = axes[1].bar(labels, final_test_losses, color=['#2E86AB', '#A23B72'], alpha=0.8, edgecolor='black')
    axes[1].set_title('Final Test Performance Comparison', fontsize=14, fontweight='bold')
    axes[1].set_ylabel('Final Test Loss (MSE)', fontsize=12)
    for bar in bars:
        height = bar.get_height()
        axes[1].text(bar.get_x() + bar.get_width() / 2.0, height, f'{height:.6f}', ha='center', va='bottom', fontsize=12, fontweight='bold')
        
    plt.tight_layout(rect=[0, 0.03, 1, 0.95])
    plot_path = save_path / 'augmentation_comparison_report.png'
    plt.savefig(plot_path, dpi=300)
    print(f"\nâœ… å°æ¯”åœ–è¡¨å·²å„²å­˜è‡³ï¼š{plot_path}")


def main():
    torch.set_float32_matmul_precision('high')
    
    parser = argparse.ArgumentParser(description='åŸ·è¡Œä¸¦æ¯”è¼ƒè³‡æ–™å¢é‡å‰å¾Œçš„å¯¦é©—')
    parser.add_argument('--config', type=str, default='configs/train_config.yaml', help='åŸºç¤è¨“ç·´è¨­å®šæª”')
    parser.add_argument('--original_data', type=str, default='./data/datasets/mango_hdf5_gelsight', help='åŸå§‹è³‡æ–™é›†è·¯å¾‘')
    parser.add_argument('--augmented_data', type=str, default='./data/datasets/mango_hdf5_augmented_5x', help='å¢é‡å¾Œè³‡æ–™é›†è·¯å¾‘')
    parser.add_argument('--skip_training', action='store_true', help='è·³éè¨“ç·´ï¼Œç›´æ¥å¾ç¾æœ‰æ—¥èªŒç”Ÿæˆåœ–è¡¨')
    args = parser.parse_args()

    config = load_config(args.config)
    
    # å®šç¾©å¯¦é©—å¾Œç¶´
    suffix1 = '_original'
    suffix2 = '_augmented'
    
    if not args.skip_training:
        print("--- å°‡é‡æ–°åŸ·è¡Œå…©æ¬¡è¨“ç·´ï¼Œé€™å¯èƒ½æœƒèŠ±è²»ä¸€äº›æ™‚é–“ ---")
        # é‡æ–°è¨“ç·´ã€ŒåŸå§‹ã€è³‡æ–™é›†
        csv_path1 = train_single_model(config, args.original_data, 'tactile', suffix1)
        # é‡æ–°è¨“ç·´ã€Œå¢é‡ã€è³‡æ–™é›†
        csv_path2 = train_single_model(config, args.augmented_data, 'tactile', suffix2)
    else:
        print("--- è·³éè¨“ç·´ï¼Œç›´æ¥ä½¿ç”¨ç¾æœ‰æ—¥èªŒé€²è¡Œåˆ†æ ---")
        log_root = Path(config['logging']['csv_dir'])
        csv_path1 = log_root / f"tactile{suffix1}" / "version_0" / "metrics.csv"
        csv_path2 = log_root / f"tactile{suffix2}" / "version_0" / "metrics.csv"

    # é€²è¡Œæœ€çµ‚åˆ†æèˆ‡ç¹ªåœ–
    if Path(csv_path1).exists() and Path(csv_path2).exists():
        analyze_and_plot(csv_path1, csv_path2, 'Original Data', 'Augmented Data', './plots')
    else:
        print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°å¿…è¦çš„æ—¥èªŒæª”æ¡ˆã€‚è«‹æª¢æŸ¥è·¯å¾‘æˆ–åŸ·è¡Œè¨“ç·´ã€‚")
        print(f"  - æ‡‰å­˜åœ¨: {csv_path1}")
        print(f"  - æ‡‰å­˜åœ¨: {csv_path2}")

if __name__ == "__main__":
    main()