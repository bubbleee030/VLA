#!/usr/bin/env python3
"""
è§¸è¦º vs åŸºç·šæ¨¡å‹å°æ¯”å¯¦é©—
è‡ªå‹•è¨“ç·´å…©å€‹æ¨¡å‹ä¸¦ç”Ÿæˆå°æ¯”åœ–è¡¨
"""

import argparse
import yaml
import torch
from pathlib import Path
from pytorch_lightning import Trainer, seed_everything
from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor
from pytorch_lightning.loggers import CSVLogger
from residual_controller.bridge_model import ResidualController
from residual_controller.controller_dataset import ControllerDataModule
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei', 'Arial Unicode MS', 'DejaVu Sans', 'Noto Sans CJK JP']
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")

def count_parameters(model):
    """è¨ˆç®—æ¨¡å‹çš„åƒæ•¸é‡"""
    total = sum(p.numel() for p in model.parameters() if p.requires_grad)
    return total


def load_config(config_path):
    """è¼‰å…¥é…ç½®æª”"""
    with open(config_path, 'r') as f:
        config = yaml.safe_load(f)
    
    # å‹åˆ¥è½‰æ›
    config['training']['epochs'] = int(config['training']['epochs'])
    config['training']['batch_size'] = int(config['training']['batch_size'])
    config['training']['learning_rate'] = float(config['training']['learning_rate'])
    config['model']['action_dim'] = int(config['model']['action_dim'])
    config['model']['obs_dim'] = int(config['model']['obs_dim'])
    config['model']['horizon'] = int(config['model']['horizon'])
    config['data']['num_workers'] = int(config['data']['num_workers'])
    
    return config

def train_single_model(config, modality, experiment_name, experiment_suffix=''):
    """è¨“ç·´å–®ä¸€æ¨¡å‹"""
    print(f"\n{'='*60}")
    print(f"ğŸš€ é–‹å§‹è¨“ç·´ï¼š{experiment_name}")
    print(f"{'='*60}\n")
    
    seed_everything(42, workers=True)
    
    # å»ºç«‹å”¯ä¸€çš„å¯¦é©—åŸ·è¡Œåç¨±
    run_name = f"{modality}{experiment_suffix}"
    print(f"ğŸ”¬ å¯¦é©—åŸ·è¡Œåç¨± (Run Name): {run_name}")
    
    # ä½¿ç”¨å”¯ä¸€çš„åç¨±ä¾†è¨­å®šè¼¸å‡ºè·¯å¾‘
    output_dir = Path(config['checkpoint']['save_dir']) / run_name
    log_dir_root = Path(config['logging']['csv_dir'])
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # DataModule
    data_module = ControllerDataModule(
        h5_path_or_dir=config['data']['data_dir'],
        batch_size=config['training']['batch_size'],
        num_workers=config['data']['num_workers']
    )
    # å‡è¨­æ‚¨å·²ç¶“ä¿®æ­£äº† dataset çš„åˆ†å‰²å’Œè·¯å¾‘å•é¡Œ
    # data_module.setup() 
    
    # Model
    model = ResidualController(
        modality=modality,
        lr=config['training']['learning_rate'],
        action_dim=config['model']['action_dim'],
        obs_dim=config['model']['obs_dim'],
        horizon=config['model']['horizon']
    )
    
    # Callbacks
    callbacks = [
        ModelCheckpoint(
            dirpath=str(output_dir),
            filename='best-{epoch:02d}-{train_loss_epoch:.4f}',
            monitor='train_loss_epoch',
            mode='min',
            save_top_k=1,
            save_last=True,
            auto_insert_metric_name=False
        ),
        LearningRateMonitor(logging_interval='epoch'),
    ]
    
    # Logger
    logger = CSVLogger(
        save_dir=str(log_dir_root),
        name=run_name,
        version=0 
    )
    
    # Trainer
    trainer = Trainer(
        max_epochs=config['training']['epochs'],
        accelerator='gpu' if torch.cuda.is_available() else 'cpu',
        devices=1,
        callbacks=callbacks,
        logger=logger,
        log_every_n_steps=config['logging']['log_every_n_steps'],
        num_sanity_val_steps=0,
        limit_val_batches=0,
        gradient_clip_val=1.0,
        deterministic=True,
        enable_progress_bar=True,
    )
    
    # è¨“ç·´
    trainer.fit(model, datamodule=data_module)
    
    log_file_path = Path(logger.log_dir) / 'metrics.csv'
    
    print(f"\nâœ… {experiment_name} è¨“ç·´å®Œæˆï¼")
    print(f"âœ… æ¨¡å‹åƒæ•¸é‡ï¼š{count_parameters(model) / 1e3:.1f}K")
    print(f"ğŸ“Š è¨˜éŒ„ä½ç½®ï¼š{log_file_path}\n")
    
    return str(log_file_path)

def load_training_metrics(csv_path):
    """è¼‰å…¥è¨“ç·´è¨˜éŒ„"""
    df = pd.read_csv(csv_path)
    # åªä¿ç•™æœ‰ epoch çš„è¨˜éŒ„ï¼ˆæ’é™¤ step-level çš„è¨˜éŒ„ï¼‰
    df_epoch = df.dropna(subset=['epoch', 'train_loss_epoch'])
    return df_epoch

def create_comparison_plots(tactile_csv, reduced_csv, save_dir='./plots'):
    """ç”Ÿæˆå°æ¯”åœ–è¡¨"""
    save_dir = Path(save_dir)
    save_dir.mkdir(parents=True, exist_ok=True)
    
    # è¼‰å…¥è³‡æ–™
    df_tactile = load_training_metrics(tactile_csv)
    df_reduced = load_training_metrics(reduced_csv)
    
    print(f"\nğŸ“Š ç”Ÿæˆå°æ¯”åœ–è¡¨...")
    print(f"  - è§¸è¦ºæ¨¡å‹è¨˜éŒ„é»æ•¸ï¼š{len(df_tactile)}")
    print(f"  - åŸºç·šæ¨¡å‹è¨˜éŒ„é»æ•¸ï¼š{len(df_reduced)}")
    
    # å»ºç«‹å¤§å‹åœ–è¡¨
    fig = plt.figure(figsize=(18, 12))
    
    # ========== åœ– 1ï¼šè¨“ç·´æå¤±å°æ¯” ==========
    ax1 = plt.subplot(2, 3, 1)
    ax1.plot(df_tactile['epoch'], df_tactile['train_loss_epoch'], 
            marker='o', linewidth=2, markersize=4, label='Complete tactile (CNN)', color='#2E86AB')
    ax1.plot(df_reduced['epoch'], df_reduced['train_loss_epoch'], 
            marker='s', linewidth=2, markersize=4, label='Reduced (Statistics)', color='#A23B72')
    ax1.set_xlabel('Epoch', fontsize=12)
    ax1.set_ylabel('Training Loss (MSE)', fontsize=12)
    ax1.set_title('Training Loss Comparison', fontsize=14, fontweight='bold')
    ax1.legend(fontsize=11)
    ax1.grid(True, alpha=0.3)
    
    # ========== åœ– 2ï¼šæœ€çµ‚æå¤±å°æ¯”ï¼ˆæŸ±ç‹€åœ–ï¼‰==========
    ax2 = plt.subplot(2, 3, 2)
    final_losses = [
        df_tactile['train_loss_epoch'].iloc[-1],
        df_reduced['train_loss_epoch'].iloc[-1]
    ]
    bars = ax2.bar(['Complete tactile\n (CNN)', 'Reduced\n (Statistics)'], final_losses, 
                   color=['#2E86AB', '#A23B72'], alpha=0.7, edgecolor='black', linewidth=2)
    ax2.set_ylabel('Final Training Loss', fontsize=12)
    ax2.set_title('Final Performance Comparison', fontsize=14, fontweight='bold')
    ax2.grid(True, alpha=0.3, axis='y')
    
    # åœ¨æŸ±å­ä¸Šæ¨™è¨»æ•¸å€¼
    for bar, loss in zip(bars, final_losses):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height,
                f'{loss:.4f}',
                ha='center', va='bottom', fontsize=11, fontweight='bold')
    
    # ========== åœ– 3ï¼šæå¤±ä¸‹é™é€Ÿåº¦å°æ¯” ==========
    ax3 = plt.subplot(2, 3, 3)
    
    # è¨ˆç®—æ¯å€‹æ¨¡å‹çš„æå¤±ä¸‹é™ç‡
    tactile_initial = df_tactile['train_loss_epoch'].iloc[0]
    tactile_final = df_tactile['train_loss_epoch'].iloc[-1]
    tactile_reduction = (1 - tactile_final / tactile_initial) * 100
    
    reduced_initial = df_reduced['train_loss_epoch'].iloc[0]
    reduced_final = df_reduced['train_loss_epoch'].iloc[-1]
    reduced_reduction = (1 - reduced_final / reduced_initial) * 100
    
    bars = ax3.bar(['Full Tactile', 'Reduced'], 
                   [tactile_reduction, reduced_reduction],
                   color=['#2E86AB', '#A23B72'], alpha=0.7, edgecolor='black', linewidth=2)
    ax3.set_ylabel('Loss Reduction (%)', fontsize=12)
    ax3.set_title('Learning Efficiency', fontsize=14, fontweight='bold')
    ax3.grid(True, alpha=0.3, axis='y')
    
    for bar, val in zip(bars, [tactile_reduction, reduced_reduction]):
        height = bar.get_height()
        ax3.text(bar.get_x() + bar.get_width()/2., height,
                f'{val:.1f}%',
                ha='center', va='bottom', fontsize=11, fontweight='bold')
    
    # ========== åœ– 4ï¼šç›¸é—œä¿‚æ•¸å°æ¯”ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰==========
    ax4 = plt.subplot(2, 3, 4)
    
    if 'train_correlation' in df_tactile.columns and 'train_correlation' in df_reduced.columns:
        df_tactile_corr = df_tactile.dropna(subset=['train_correlation'])
        df_reduced_corr = df_reduced.dropna(subset=['train_correlation'])
        
        if len(df_tactile_corr) > 0 and len(df_reduced_corr) > 0:
            ax4.plot(df_tactile_corr['epoch'], df_tactile_corr['train_correlation'],
                    marker='o', linewidth=2, markersize=4, label='Full Tactile', color='#2E86AB')
            ax4.plot(df_reduced_corr['epoch'], df_reduced_corr['train_correlation'],
                    marker='s', linewidth=2, markersize=4, label='Reduced', color='#A23B72')
            ax4.axhline(y=0.9, color='red', linestyle='--', alpha=0.5, label='Target (0.9)')
            ax4.set_xlabel('Epoch', fontsize=12)
            ax4.set_ylabel('Correlation', fontsize=12)
            ax4.set_title('Prediction Correlation', fontsize=14, fontweight='bold')
            ax4.legend(fontsize=10)
            ax4.grid(True, alpha=0.3)
            ax4.set_ylim([0, 1])
        else:
            ax4.text(0.5, 0.5, 'No Correlation Data', ha='center', va='center', fontsize=14)
            ax4.axis('off')
    else:
        ax4.text(0.5, 0.5, 'No Correlation Data', ha='center', va='center', fontsize=14)
        ax4.axis('off')
    
    # ========== åœ– 5ï¼šæ”¶æ–‚é€Ÿåº¦å°æ¯” ==========
    ax5 = plt.subplot(2, 3, 5)
    
    # æ‰¾åˆ°é”åˆ°ç‰¹å®šæå¤±é–¾å€¼æ‰€éœ€çš„ epoch
    threshold = 0.01  # è¨­å®šä¸€å€‹æå¤±é–¾å€¼
    
    tactile_converge = df_tactile[df_tactile['train_loss_epoch'] < threshold]
    reduced_converge = df_reduced[df_reduced['train_loss_epoch'] < threshold]
    
    if len(tactile_converge) > 0 and len(reduced_converge) > 0:
        tactile_epoch = tactile_converge['epoch'].iloc[0]
        reduced_epoch = reduced_converge['epoch'].iloc[0]
        
        bars = ax5.barh(['Full Tactile', 'Reduced'], [tactile_epoch, reduced_epoch],
                       color=['#2E86AB', '#A23B72'], alpha=0.7, edgecolor='black', linewidth=2)
        ax5.set_xlabel('Epochs to Reach Loss < 0.01', fontsize=12)
        ax5.set_title('Convergence Speed', fontsize=14, fontweight='bold')
        ax5.grid(True, alpha=0.3, axis='x')
        
        for bar, val in zip(bars, [tactile_epoch, reduced_epoch]):
            width = bar.get_width()
            ax5.text(width, bar.get_y() + bar.get_height()/2.,
                    f'{int(val)}',
                    ha='left', va='center', fontsize=11, fontweight='bold', 
                    bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.5))
    else:
        ax5.text(0.5, 0.5, 'Convergence Not Reached', ha='center', va='center', fontsize=14)
        ax5.axis('off')
    
    # ========== åœ– 6ï¼šæ¨¡å‹åƒæ•¸é‡å°æ¯” ==========
    ax6 = plt.subplot(2, 3, 6)
    
    # å¾æ¨¡å‹æ¶æ§‹ä¼°ç®—åƒæ•¸é‡ï¼ˆæ‚¨éœ€è¦æ ¹æ“šå¯¦éš›æƒ…æ³èª¿æ•´ï¼‰
    tactile_params = 705  # å¾æ‚¨ä¹‹å‰çš„è¨“ç·´çµæœï¼š705K åƒæ•¸
    reduced_params = 100  # ä¼°ç®—å€¼ï¼ˆå› ç‚ºæ²’æœ‰ CNNï¼‰

    bars = ax6.bar(['Complete Tactile\n(CNN)', 'Reduced\n(Statistics)'],
                   [tactile_params, reduced_params],
                   color=['#2E86AB', '#A23B72'], alpha=0.7, edgecolor='black', linewidth=2)
    ax6.set_ylabel('Parameters (K)', fontsize=12)
    ax6.set_title('Model Complexity', fontsize=14, fontweight='bold')
    ax6.grid(True, alpha=0.3, axis='y')
    
    for bar, val in zip(bars, [tactile_params, reduced_params]):
        height = bar.get_height()
        ax6.text(bar.get_x() + bar.get_width()/2., height,
                f'{val}K',
                ha='center', va='bottom', fontsize=11, fontweight='bold')
    
    # æ•´é«”æ¨™é¡Œ
    fig.suptitle('Tactile Sensor Value: Full vs Reduced Baseline', 
                 fontsize=18, fontweight='bold', y=0.98)
    
    plt.tight_layout(rect=[0, 0, 1, 0.96])
    
    # å„²å­˜
    plot_path = save_dir / 'tactile_comparison.png'
    plt.savefig(plot_path, dpi=300, bbox_inches='tight')
    print(f"âœ… å°æ¯”åœ–è¡¨å·²å„²å­˜ï¼š{plot_path}")
    
    pdf_path = save_dir / 'tactile_comparison.pdf'
    plt.savefig(pdf_path, bbox_inches='tight')
    print(f"âœ… PDF å·²å„²å­˜ï¼š{pdf_path}")
    
    plt.show()
    
    # ========== ç”Ÿæˆçµ±è¨ˆå ±å‘Š ==========
    print_comparison_report(df_tactile, df_reduced)

def print_comparison_report(df_tactile, df_reduced):
    """åˆ—å°çµ±è¨ˆå ±å‘Š"""
    print("\n" + "="*70)
    print("ğŸ“Š è§¸è¦ºæ„Ÿæ¸¬å™¨åƒ¹å€¼é‡åŒ–åˆ†æå ±å‘Š")
    print("="*70)
    
    # è¨ˆç®—é—œéµæŒ‡æ¨™
    tactile_final = df_tactile['train_loss_epoch'].iloc[-1]
    reduced_final = df_reduced['train_loss_epoch'].iloc[-1]
    improvement = (reduced_final - tactile_final) / reduced_final * 100
    
    print(f"\nã€æœ€çµ‚æ€§èƒ½å°æ¯”ã€‘")
    print(f"  å®Œæ•´è§¸è¦ºæ¨¡å‹æœ€çµ‚æå¤±ï¼š{tactile_final:.6f}")
    print(f"  é€€åŒ–ç‰ˆæ¨¡å‹æœ€çµ‚æå¤±ï¼š{reduced_final:.6f}")
    print(f"  æ€§èƒ½æå‡ï¼š{improvement:.2f}%")
    
    if improvement > 50:
        print(f"  âœ… çµè«–ï¼šå®Œæ•´è§¸è¦ºé¡¯è‘—å„ªæ–¼é€€åŒ–ç‰ˆï¼Œç©ºé–“è³‡è¨Šè‡³é—œé‡è¦")
    elif improvement > 20:
        print(f"  âœ… çµè«–ï¼šå®Œæ•´è§¸è¦ºæ˜é¡¯å„ªæ–¼é€€åŒ–ç‰ˆï¼Œè­‰æ˜è§¸è¦ºçš„åƒ¹å€¼")
    elif improvement > 5:
        print(f"  âš ï¸  çµè«–ï¼šå®Œæ•´è§¸è¦ºç•¥å„ªæ–¼é€€åŒ–ç‰ˆ")
    else:
        print(f"  âš ï¸  çµè«–ï¼šå…©è€…æ€§èƒ½æ¥è¿‘ï¼Œéœ€è¦é€²ä¸€æ­¥åˆ†æ")
    
    print(f"\nã€å­¸ç¿’æ›²ç·šåˆ†æã€‘")
    tactile_std = df_tactile['train_loss_epoch'].std()
    reduced_std = df_reduced['train_loss_epoch'].std()
    
    print(f"  å®Œæ•´è§¸è¦ºæ¨¡å‹å­¸ç¿’ç©©å®šæ€§ï¼ˆæ¨™æº–å·®ï¼‰ï¼š{tactile_std:.6f}")
    print(f"  é€€åŒ–ç‰ˆæ¨¡å‹å­¸ç¿’ç©©å®šæ€§ï¼ˆæ¨™æº–å·®ï¼‰ï¼š{reduced_std:.6f}")
    
    print("="*70 + "\n")

def main():
    parser = argparse.ArgumentParser(description='è§¸è¦º vs åŸºç·šæ¨¡å‹å°æ¯”å¯¦é©—')
    parser.add_argument('--config', type=str, default='configs/train_config.yaml')
    parser.add_argument('--skip_training', action='store_true', 
                        help='è·³éè¨“ç·´ï¼Œåªç”Ÿæˆåœ–è¡¨ï¼ˆéœ€è¦å·²æœ‰è¨“ç·´è¨˜éŒ„ï¼‰')
    parser.add_argument('--experiment_suffix', type=str, default='', help='ç‚ºå¯¦é©—æ—¥èªŒå’Œè¼¸å‡ºåŠ ä¸Šå¾Œç¶´ï¼Œä»¥å€åˆ†ä¸åŒå¯¦é©—')
    args = parser.parse_args()
    
    config = load_config(args.config)
    
    if not args.skip_training:
        # è¨“ç·´å®Œæ•´è§¸è¦ºæ¨¡å‹
        tactile_csv = train_single_model(config, 'tactile', 'å®Œæ•´è§¸è¦ºæ¨¡å‹ (CNN)')
        args.experiment_suffix
        # è¨“ç·´é€€åŒ–ç‰ˆæ¨¡å‹
        reduced_csv = train_single_model(config, 'tactile_reduced', 'é€€åŒ–ç‰ˆæ¨¡å‹ (çµ±è¨ˆç‰¹å¾µ)')
        args.experiment_suffix
    else:
        print("â­ï¸  è·³éè¨“ç·´ï¼Œä½¿ç”¨ç¾æœ‰è¨˜éŒ„...")
        tactile_csv = './logs/csv/tactile/comparison/metrics.csv'
        reduced_csv = './logs/csv/tactile_reduced/comparison/metrics.csv'
    
    # ç”Ÿæˆå°æ¯”åœ–è¡¨
    create_comparison_plots(tactile_csv, reduced_csv, save_dir='./plots')
    
    print("\n" + "="*70)
    print("âœ… å°æ¯”å¯¦é©—å®Œæˆï¼")
    print("="*70)
    print(f"\nğŸ“ æª”æ¡ˆä½ç½®ï¼š")
    print(f"  - å®Œæ•´è§¸è¦ºæ¨¡å‹æª¢æŸ¥é»ï¼š./outputs/tactile/")
    print(f"  - é€€åŒ–ç‰ˆæ¨¡å‹æª¢æŸ¥é»ï¼š./outputs/tactile_reduced/")
    print(f"  - å°æ¯”åœ–è¡¨ï¼š./plots/tactile_comparison.png")
    print(f"  - PDF ç‰ˆæœ¬ï¼š./plots/tactile_comparison.pdf")
    print("="*70 + "\n")

if __name__ == "__main__":
    main()