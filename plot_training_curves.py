#!/usr/bin/env python3
"""
è¨“ç·´æ›²ç·šè¦–è¦ºåŒ–è…³æœ¬
è‡ªå‹•è®€å– CSV logs ä¸¦ç”Ÿæˆç²¾ç¾çš„è¨“ç·´æ›²ç·šåœ–
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import argparse

# è¨­å®šä¸­æ–‡å­—é«”å’Œé¢¨æ ¼
plt.rcParams['font.sans-serif'] = ['Noto Sans CJK JP', 'Microsoft JhengHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")
sns.set_palette("husl")

def find_latest_csv(csv_dir):
    """æ‰¾åˆ°æœ€æ–°çš„ CSV log æª”æ¡ˆ"""
    csv_dir = Path(csv_dir)
    csv_files = list(csv_dir.glob("**/metrics.csv"))
    
    if not csv_files:
        raise FileNotFoundError(f"åœ¨ {csv_dir} ä¸­æ‰¾ä¸åˆ° metrics.csv æª”æ¡ˆ")
    
    # é¸æ“‡æœ€æ–°çš„æª”æ¡ˆ
    latest_csv = max(csv_files, key=lambda p: p.stat().st_mtime)
    print(f"ğŸ“Š è®€å–è¨“ç·´è¨˜éŒ„ï¼š{latest_csv}")
    return latest_csv

def plot_training_curves(csv_path, save_dir='./plots'):
    """ç¹ªè£½è¨“ç·´æ›²ç·š"""
    # è®€å–è³‡æ–™
    df = pd.read_csv(csv_path)
    print(f"ğŸ“ˆ è³‡æ–™é»æ•¸é‡ï¼š{len(df)}")
    print(f"ğŸ“‹ å¯ç”¨æ¬„ä½ï¼š{df.columns.tolist()}")
    
    # å»ºç«‹è¼¸å‡ºç›®éŒ„
    save_dir = Path(save_dir)
    save_dir.mkdir(parents=True, exist_ok=True)
    
    # å»ºç«‹åœ–è¡¨
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('è§¸è¦ºæ§åˆ¶å™¨è¨“ç·´æ›²ç·šåˆ†æ', fontsize=20, fontweight='bold')
    
    # ========== åœ– 1ï¼šè¨“ç·´ Loss (Epoch Level) ==========
    ax1 = axes[0, 0]
    if 'train_loss_epoch' in df.columns:
        epoch_data = df.dropna(subset=['train_loss_epoch'])
        ax1.plot(epoch_data['epoch'], epoch_data['train_loss_epoch'], 
                marker='o', linewidth=2, markersize=6, label='Train Loss', color='#E74C3C')
        ax1.set_xlabel('Epoch', fontsize=12)
        ax1.set_ylabel('Loss (MSE)', fontsize=12)
        ax1.set_title('è¨“ç·´æå¤±å‡½æ•¸ (Train Loss)', fontsize=14, fontweight='bold')
        ax1.legend(fontsize=11)
        ax1.grid(True, alpha=0.3)
        
        # æ¨™è¨»æœ€ä½é»
        min_idx = epoch_data['train_loss_epoch'].idxmin()
        min_epoch = epoch_data.loc[min_idx, 'epoch']
        min_loss = epoch_data.loc[min_idx, 'train_loss_epoch']
        ax1.annotate(f'æœ€ä½: {min_loss:.4f}', 
                    xy=(min_epoch, min_loss),
                    xytext=(10, 10), textcoords='offset points',
                    bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.7),
                    arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))
    
    # ========== åœ– 2ï¼šStep Level Loss (æ›´ç´°ç·») ==========
    ax2 = axes[0, 1]
    if 'train_loss_step' in df.columns:
        step_data = df.dropna(subset=['train_loss_step'])
        ax2.plot(step_data['step'], step_data['train_loss_step'], 
                linewidth=1, alpha=0.6, color='#3498DB', label='Step Loss')
        
        # åŠ ä¸Šæ»‘å‹•å¹³å‡
        window = min(50, len(step_data) // 10)
        if window > 1:
            rolling_mean = step_data['train_loss_step'].rolling(window=window).mean()
            ax2.plot(step_data['step'], rolling_mean, 
                    linewidth=2.5, color='#E67E22', label=f'æ»‘å‹•å¹³å‡ (çª—å£={window})')
        
        ax2.set_xlabel('è¨“ç·´æ­¥æ•¸ (Step)', fontsize=12)
        ax2.set_ylabel('Loss (MSE)', fontsize=12)
        ax2.set_title('è¨“ç·´æå¤±å‡½æ•¸ (Step Level)', fontsize=14, fontweight='bold')
        ax2.legend(fontsize=11)
        ax2.grid(True, alpha=0.3)
    
    # ========== åœ– 3ï¼šç›¸é—œä¿‚æ•¸ (Correlation) ==========
    ax3 = axes[1, 0]
    if 'train_correlation' in df.columns:
        corr_data = df.dropna(subset=['train_correlation'])
        ax3.plot(corr_data['epoch'], corr_data['train_correlation'], 
                marker='s', linewidth=2, markersize=6, label='Correlation', color='#27AE60')
        ax3.axhline(y=0.9, color='red', linestyle='--', alpha=0.5, label='ç›®æ¨™ (0.9)')
        ax3.set_xlabel('Epoch', fontsize=12)
        ax3.set_ylabel('ç›¸é—œä¿‚æ•¸ (Pearson)', fontsize=12)
        ax3.set_title('é æ¸¬ç›¸é—œæ€§åˆ†æ', fontsize=14, fontweight='bold')
        ax3.legend(fontsize=11)
        ax3.grid(True, alpha=0.3)
        ax3.set_ylim([0, 1])
    
    # ========== åœ– 4ï¼šå­¸ç¿’ç‡è®ŠåŒ– ==========
    ax4 = axes[1, 1]
    if 'learning_rate' in df.columns:
        lr_data = df.dropna(subset=['learning_rate'])
        ax4.plot(lr_data['epoch'], lr_data['learning_rate'], 
                marker='D', linewidth=2, markersize=6, label='Learning Rate', color='#9B59B6')
        ax4.set_xlabel('Epoch', fontsize=12)
        ax4.set_ylabel('å­¸ç¿’ç‡', fontsize=12)
        ax4.set_title('å­¸ç¿’ç‡èª¿åº¦', fontsize=14, fontweight='bold')
        ax4.set_yscale('log')  # ä½¿ç”¨å°æ•¸åˆ»åº¦
        ax4.legend(fontsize=11)
        ax4.grid(True, alpha=0.3, which='both')
    
    plt.tight_layout()
    
    # å„²å­˜åœ–è¡¨
    plot_path = save_dir / 'training_curves.png'
    plt.savefig(plot_path, dpi=300, bbox_inches='tight')
    print(f"âœ… åœ–è¡¨å·²å„²å­˜ï¼š{plot_path}")
    
    # ä¹Ÿå„²å­˜æˆ PDFï¼ˆå‘é‡åœ–ï¼Œé©åˆè«–æ–‡ï¼‰
    pdf_path = save_dir / 'training_curves.pdf'
    plt.savefig(pdf_path, bbox_inches='tight')
    print(f"âœ… PDF å·²å„²å­˜ï¼š{pdf_path}")
    
    plt.show()
    
    # ========== è¼¸å‡ºçµ±è¨ˆæ‘˜è¦ ==========
    print("\n" + "="*50)
    print("ğŸ“Š è¨“ç·´çµ±è¨ˆæ‘˜è¦")
    print("="*50)
    
    if 'train_loss_epoch' in df.columns:
        epoch_data = df.dropna(subset=['train_loss_epoch'])
        print(f"\nã€è¨“ç·´ Lossã€‘")
        print(f"  åˆå§‹ Loss: {epoch_data['train_loss_epoch'].iloc[0]:.6f}")
        print(f"  æœ€çµ‚ Loss: {epoch_data['train_loss_epoch'].iloc[-1]:.6f}")
        print(f"  æœ€ä½ Loss: {epoch_data['train_loss_epoch'].min():.6f} (Epoch {epoch_data.loc[epoch_data['train_loss_epoch'].idxmin(), 'epoch']:.0f})")
        print(f"  Loss ä¸‹é™: {(1 - epoch_data['train_loss_epoch'].iloc[-1]/epoch_data['train_loss_epoch'].iloc[0])*100:.2f}%")
    
    if 'train_correlation' in df.columns:
        corr_data = df.dropna(subset=['train_correlation'])
        print(f"\nã€é æ¸¬ç›¸é—œæ€§ã€‘")
        print(f"  æœ€çµ‚ç›¸é—œä¿‚æ•¸: {corr_data['train_correlation'].iloc[-1]:.4f}")
        print(f"  æœ€é«˜ç›¸é—œä¿‚æ•¸: {corr_data['train_correlation'].max():.4f}")

def main():
    parser = argparse.ArgumentParser(description='ç¹ªè£½è¨“ç·´æ›²ç·š')
    parser.add_argument('--csv_dir', type=str, default='./logs/csv',
                        help='CSV logs ç›®éŒ„')
    parser.add_argument('--save_dir', type=str, default='./plots',
                        help='åœ–è¡¨å„²å­˜ç›®éŒ„')
    args = parser.parse_args()
    
    try:
        csv_path = find_latest_csv(args.csv_dir)
        plot_training_curves(csv_path, args.save_dir)
    except Exception as e:
        print(f"âŒ éŒ¯èª¤ï¼š{e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()