#!/usr/bin/env python3
"""
æ–‡å­—æŒ‡ä»¤ç³»çµ±å±•ç¤ºè…³æœ¬
- å°‡ä½¿ç”¨è€…è¼¸å…¥çš„æ–‡å­—æŒ‡ä»¤è½‰æ›ç‚ºåµŒå…¥å‘é‡
- æ¨¡æ“¬å°‡æ­¤å‘é‡ä½œç‚ºæ¨¡å‹è¼¸å…¥çš„éç¨‹
"""

from sentence_transformers import SentenceTransformer
import torch
import numpy as np

def get_text_embedding(instruction_text, model_name="clip-ViT-L-14"):
    """
    å°‡æ–‡å­—æŒ‡ä»¤è½‰æ›ç‚ºåµŒå…¥å‘é‡
    """
    print(f"ğŸ§  æ­£åœ¨ä½¿ç”¨ '{model_name}' æ¨¡å‹ä¾†ç†è§£æ‚¨çš„æŒ‡ä»¤...")
    
    # è¼‰å…¥é è¨“ç·´çš„ CLIP-style æ¨¡å‹
    model = SentenceTransformer(model_name)
    
    # å°‡æ–‡å­—ç·¨ç¢¼ç‚ºåµŒå…¥å‘é‡
    embedding = model.encode(instruction_text, convert_to_tensor=True)
    
    print(f"âœ… æŒ‡ä»¤ '{instruction_text}' å·²è½‰æ›ç‚ºåµŒå…¥å‘é‡")
    print(f"   å‘é‡ç¶­åº¦ï¼š{embedding.shape}") # æ‡‰è©²æ˜¯ [768]
    
    return embedding

def main():
    print("="*60)
    print("ğŸ—£ï¸ æ­¡è¿ä½¿ç”¨ VLA æ–‡å­—æŒ‡ä»¤ç³»çµ±")
    print("="*60)
    print("æ‚¨å¯ä»¥è¼¸å…¥ä»»ä½•æ“ä½œæŒ‡ä»¤ï¼Œä¾‹å¦‚ï¼š")
    print("  - è‹±æ–‡: 'pick up the mango and place it in the bowl'")
    print("  - ä¸­æ–‡: 'è«‹æŠŠèŠ’æœæ‹¿èµ·ä¾†ï¼Œç„¶å¾Œæ”¾åˆ°ç¢—è£¡'")
    print("\nè¼¸å…¥ 'exit' æˆ– 'q' ä¾†é›¢é–‹ç¨‹å¼ã€‚\n")

    while True:
        # è®“ä½¿ç”¨è€…è¼¸å…¥æŒ‡ä»¤
        user_command = input("ğŸ‘‰ è«‹è¼¸å…¥æ‚¨çš„æŒ‡ä»¤ï¼š")
        
        if user_command.lower() in ['exit', 'q']:
            print("ğŸ‘‹ ç¨‹å¼çµæŸã€‚")
            break
        
        if not user_command:
            continue
        
        # 1. å–å¾—æŒ‡ä»¤çš„åµŒå…¥å‘é‡
        instruction_embedding = get_text_embedding(user_command)
        
        # 2. æ¨¡æ“¬å°‡å…¶ä½œç‚ºæ¨¡å‹è¼¸å…¥
        # åœ¨çœŸå¯¦çš„ VLA ä¸­ï¼Œé€™å€‹å‘é‡æœƒèˆ‡å½±åƒç‰¹å¾µã€æ©Ÿå™¨äººç‹€æ…‹ç‰¹å¾µä¸€èµ·è¢«èåˆ
        print("\n--- æ¨¡æ“¬æ¨¡å‹æ¨æ–·æµç¨‹ ---")
        print("1. âœ… æ–‡å­—æŒ‡ä»¤å·²ç·¨ç¢¼")
        print("2. ğŸ‘ï¸ (æ¨¡æ“¬) å–å¾—æ”å½±æ©Ÿå½±åƒï¼Œä¸¦ç”¨ ViT ç·¨ç¢¼")
        print("3. ğŸ¤š (æ¨¡æ“¬) å–å¾— GelSight å½±åƒï¼Œä¸¦ç”¨ CNN ç·¨ç¢¼")
        print("4. ğŸ¦¾ (æ¨¡æ“¬) å–å¾—æ©Ÿå™¨äººé—œç¯€ç‹€æ…‹ï¼Œä¸¦ç”¨ MLP ç·¨ç¢¼")
        
        # 5. å°‡æ‰€æœ‰ç‰¹å¾µèåˆ
        # fusion_input = torch.cat([instruction_embedding, vision_features, tactile_features, ...])
        print("\n5. âš™ï¸ (æ¨¡æ“¬) å°‡æ–‡å­—å‘é‡èˆ‡å…¶ä»–æ„Ÿæ¸¬å™¨ç‰¹å¾µèåˆ...")
        print(f"   èåˆå¾Œçš„ç‰¹å¾µå°‡æœƒè¢«è¼¸å…¥åˆ°æ±ºç­–ç¶²è·¯ (Transformer)ã€‚")
        
        # 6. å„²å­˜åµŒå…¥å‘é‡ä»¥ä¾›çœŸå¯¦æ¨¡å‹ä½¿ç”¨
        save_path = "./instruction_embedding_custom.npy"
        np.save(save_path, instruction_embedding.cpu().numpy())
        print(f"\nğŸ’¾ æ‚¨çš„æŒ‡ä»¤åµŒå…¥å‘é‡å·²å„²å­˜åˆ°ï¼š{save_path}")
        print("   æ‚¨å¯ä»¥å°‡é€™å€‹æª”æ¡ˆè¼‰å…¥åˆ°çœŸå¯¦çš„æ¨æ–·è…³æœ¬ä¸­ï¼")
        print("----------------------------\n")
        

if __name__ == "__main__":
    main()